{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f72765-879d-433b-b6ae-f357fe7494f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e86191-3aea-4660-b9ed-07f21e8d1f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7b4d57-dffc-4508-9746-570354a528a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:26.431195Z",
     "iopub.status.busy": "2025-11-13T17:30:26.430869Z",
     "iopub.status.idle": "2025-11-13T17:30:26.434446Z",
     "shell.execute_reply": "2025-11-13T17:30:26.433916Z",
     "shell.execute_reply.started": "2025-11-13T17:30:26.431181Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a561f5-d8ac-4c7e-8fc2-a3c115e3ba3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:26.807556Z",
     "iopub.status.busy": "2025-11-13T17:30:26.807406Z",
     "iopub.status.idle": "2025-11-13T17:30:26.814532Z",
     "shell.execute_reply": "2025-11-13T17:30:26.814072Z",
     "shell.execute_reply.started": "2025-11-13T17:30:26.807545Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_lightcurve_file(filename):\n",
    "    \"\"\"\n",
    "    Read the lightcurve file and extract header parameters and data\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract header info\n",
    "    header_params = {}\n",
    "    data_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('#'):\n",
    "            # Parse header lines\n",
    "            if '=' in line:\n",
    "                key_value = line[1:].strip().split('=')\n",
    "                if len(key_value) == 2:\n",
    "                    key = key_value[0].strip()\n",
    "                    value = key_value[1].strip()\n",
    "                    header_params[key] = value\n",
    "        else:\n",
    "            # Only add non-empty lines that don't start with #\n",
    "            if line.strip() and not line.strip().startswith('#'):\n",
    "                data_lines.append(line.strip())\n",
    "    \n",
    "    # Convert data to numpy array\n",
    "    if data_lines:\n",
    "        try:\n",
    "            data_array = np.genfromtxt(data_lines)\n",
    "            \n",
    "            # Check if we have enough columns\n",
    "            if data_array.ndim == 1:\n",
    "                # Single row case\n",
    "                data_array = data_array.reshape(1, -1)\n",
    "            \n",
    "            # Define column names based on your description\n",
    "            column_names = ['Simulation_time', 'measured_relative_flux', 'measured_relative_flux_error', \n",
    "                           'true_relative_flux', 'true_relative_flux_error', 'observatory_code', \n",
    "                           'saturation_flag', 'best_single_lens_fit', 'parallax_shift_t', 'parallax_shift_u',\n",
    "                           'BJD', 'source_x', 'source_y', 'lens1_x', 'lens1_y', 'lens2_x', 'lens2_y']\n",
    "            \n",
    "            # Create dictionary with column data\n",
    "            for i, col_name in enumerate(column_names):\n",
    "                if i < data_array.shape[1]:\n",
    "                    data[col_name] = data_array[:, i]\n",
    "                else:\n",
    "                    data[col_name] = np.array([])\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing data from {filename}: {e}\")\n",
    "            data = None\n",
    "    else:\n",
    "        data = None\n",
    "    \n",
    "    return header_params, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0deb00-7b80-4a5c-94ab-d5c2bfe266bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:27.064394Z",
     "iopub.status.busy": "2025-11-13T17:30:27.064242Z",
     "iopub.status.idle": "2025-11-13T17:30:27.070463Z",
     "shell.execute_reply": "2025-11-13T17:30:27.070044Z",
     "shell.execute_reply.started": "2025-11-13T17:30:27.064383Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_and_process_tar_files():\n",
    "    \"\"\"\n",
    "    Extract all tar.gz files and process the lightcurve files\n",
    "    \"\"\"\n",
    "    # Find all tar.gz files in current directory \n",
    "    tar_files = glob.glob('OMPLDG_croin_cassan_*.tar.gz') #glob helps find files whose names have a specific pattern\n",
    "    \n",
    "    # If no files found with correct pattern, try the pattern from your error message\n",
    "    if not tar_files:\n",
    "        tar_files = glob.glob('OWPLOG_croin_cassan_*.tar.gz')\n",
    "    \n",
    "    if not tar_files:\n",
    "        print(\"No tar files found! Looking for files in current directory:\")\n",
    "        print(\"Files in current directory:\", os.listdir('.'))\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Found {len(tar_files)} tar files to process\") #number of tar files found\n",
    "    all_parameters = {}\n",
    "    \n",
    "    for tar_file in tar_files:\n",
    "        #print(f\"Processing {tar_file}...\")\n",
    "        \n",
    "        # Extract tar file\n",
    "        with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "            # Get list of all files in tar\n",
    "            file_list = tar.getnames()\n",
    "            #print(f\"  Files in archive: {file_list}\")\n",
    "            \n",
    "            # Extract to a temporary directory\n",
    "            extract_dir = f\"temp_{tar_file.replace('.tar.gz', '')}\"\n",
    "            tar.extractall(extract_dir)\n",
    "        \n",
    "        # Find all files in the extracted directory (recursively)\n",
    "        all_files = []\n",
    "        for root, dirs, files in os.walk(extract_dir):\n",
    "            for file in files:\n",
    "                all_files.append(os.path.join(root, file))\n",
    "        \n",
    "        print(f\"  Found {len(all_files)} total files in extracted directory\")\n",
    "        \n",
    "        file_parameters = []\n",
    "        \n",
    "        for file_path in all_files:\n",
    "            # Try to process any file that might be a lightcurve\n",
    "            try:\n",
    "                header_params, data = read_lightcurve_file(file_path)\n",
    "                if data is not None and len(data) > 0 and 'Simulation_time' in data:\n",
    "                    # Calculate some basic statistics for this lightcurve\n",
    "                    stats = {\n",
    "                        'filename': os.path.basename(file_path),\n",
    "                        'header_params': header_params,\n",
    "                        'data_stats': {\n",
    "                            'num_points': len(data['Simulation_time']),\n",
    "                            'time_range': [np.min(data['Simulation_time']), np.max(data['Simulation_time'])],\n",
    "                            'mean_measured_flux': np.mean(data['measured_relative_flux']),\n",
    "                            'std_measured_flux': np.std(data['measured_relative_flux']),\n",
    "                            'mean_true_flux': np.mean(data['true_relative_flux']),\n",
    "                            'std_true_flux': np.std(data['true_relative_flux']),\n",
    "                        },\n",
    "                        'data': data  # Store the actual data for plotting\n",
    "                    }\n",
    "                    file_parameters.append(stats)\n",
    "                    #print(f\"    Successfully processed: {os.path.basename(file_path)} - {len(data['Simulation_time'])} data points\")\n",
    "            except Exception as e:\n",
    "                # Skip files that can't be processed\n",
    "                continue\n",
    "        \n",
    "        all_parameters[tar_file] = file_parameters\n",
    "        #print(f\"  Successfully processed {len(file_parameters)} lightcurves from {tar_file}\")\n",
    "        \n",
    "        # Clean up extracted files\n",
    "        import shutil\n",
    "        shutil.rmtree(extract_dir)\n",
    "    \n",
    "    return all_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11f472c-c001-40e8-ae3f-2e186cc1b3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:27.400542Z",
     "iopub.status.busy": "2025-11-13T17:30:27.400398Z",
     "iopub.status.idle": "2025-11-13T17:30:27.408208Z",
     "shell.execute_reply": "2025-11-13T17:30:27.407755Z",
     "shell.execute_reply.started": "2025-11-13T17:30:27.400532Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_parameter_distributions(all_parameters):\n",
    "    \"\"\"\n",
    "    Create plots to visualize distributions of various parameters\n",
    "    \"\"\"\n",
    "    # Collect data from all files\n",
    "    all_measured_flux = []\n",
    "    all_true_flux = []\n",
    "    all_flux_errors = []\n",
    "    all_num_points = []\n",
    "    all_time_ranges = []\n",
    "    \n",
    "    # Also collect some example light curves for visualization\n",
    "    #example_lightcurves = []\n",
    "    \n",
    "    for tar_file, file_params_list in all_parameters.items():\n",
    "        for file_params in file_params_list:\n",
    "            stats = file_params['data_stats']\n",
    "            all_measured_flux.append(stats['mean_measured_flux'])\n",
    "            all_true_flux.append(stats['mean_true_flux'])\n",
    "            all_flux_errors.append(stats['std_measured_flux'])\n",
    "            all_num_points.append(stats['num_points'])\n",
    "            time_range = stats['time_range'][1] - stats['time_range'][0]\n",
    "            all_time_ranges.append(time_range)\n",
    "            \n",
    "            # Store a few example lightcurves for plotting\n",
    "            #if len(example_lightcurves) < 5:  # Store up to 5 examples\n",
    "                #example_lightcurves.append(file_params)\n",
    "    \n",
    "    # Check if we have any data to plot\n",
    "    if not all_measured_flux:\n",
    "        print(\"No data found to plot!\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Light Curve Parameter Distributions', fontsize=16)\n",
    "    \n",
    "    # Plot 1: Distribution of mean measured flux\n",
    "    axes[0, 0].hist(all_measured_flux, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Mean Measured Relative Flux')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Mean Measured Flux')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Distribution of mean true flux\n",
    "    axes[0, 1].hist(all_true_flux, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axes[0, 1].set_xlabel('Mean True Relative Flux')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Distribution of Mean True Flux')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Distribution of flux errors\n",
    "    axes[0, 2].hist(all_flux_errors, bins=20, alpha=0.7, edgecolor='black', color='green')\n",
    "    axes[0, 2].set_xlabel('Standard Deviation of Measured Flux')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].set_title('Distribution of Flux Errors')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Number of data points per lightcurve\n",
    "    axes[1, 0].hist(all_num_points, bins=20, alpha=0.7, edgecolor='black', color='purple')\n",
    "    axes[1, 0].set_xlabel('Number of Data Points')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Distribution of Data Points per Lightcurve')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Time range distribution\n",
    "    axes[1, 1].hist(all_time_ranges, bins=20, alpha=0.7, edgecolor='black', color='red')\n",
    "    axes[1, 1].set_xlabel('Time Range')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of Time Ranges')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Example light curves\n",
    "   # if example_lightcurves:\n",
    "    #    for i, example in enumerate(example_lightcurves):\n",
    "         #   data = example['data']\n",
    "        #    axes[1, 2].plot(data['Simulation_time'], data['measured_relative_flux'], \n",
    "                           #'o-', markersize=2, alpha=0.7, label=f'Example {i+1}')\n",
    "       # axes[1, 2].set_xlabel('Simulation Time')\n",
    "       # axes[1, 2].set_ylabel('Measured Relative Flux')\n",
    "        #axes[1, 2].set_title('Example Light Curves')\n",
    "       # axes[1, 2].legend(fontsize=8)\n",
    "       # axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lightcurve_parameter_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create additional plot: show header parameter information\n",
    "    plot_header_parameters(all_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b3edb8-d528-4483-b53f-1f2dd3b6ac12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:27.605068Z",
     "iopub.status.busy": "2025-11-13T17:30:27.604899Z",
     "iopub.status.idle": "2025-11-13T17:30:27.610188Z",
     "shell.execute_reply": "2025-11-13T17:30:27.609756Z",
     "shell.execute_reply.started": "2025-11-13T17:30:27.605055Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_header_parameters(all_parameters):\n",
    "    \"\"\"\n",
    "    Plot distributions of header parameters if available\n",
    "    \"\"\"\n",
    "    # Collect header parameters\n",
    "    fs_values = []\n",
    "    mag_values = []\n",
    "    \n",
    "    for tar_file, file_params_list in all_parameters.items():\n",
    "        for file_params in file_params_list:\n",
    "            header = file_params['header_params']\n",
    "            if 'fs' in header:\n",
    "                try:\n",
    "                    fs_values.append(float(header['fs']))\n",
    "                except:\n",
    "                    pass\n",
    "            # Look for magnitude parameters\n",
    "            for key, value in header.items():\n",
    "                if 'mag' in key.lower():\n",
    "                    try:\n",
    "                        mag_values.append(float(value))\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    if fs_values or mag_values:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        fig.suptitle('Header Parameter Distributions', fontsize=16)\n",
    "        \n",
    "        if fs_values:\n",
    "            axes[0].hist(fs_values, bins=20, alpha=0.7, edgecolor='black', color='blue')\n",
    "            axes[0].set_xlabel('fs values')\n",
    "            axes[0].set_ylabel('Frequency')\n",
    "            axes[0].set_title('Distribution of fs parameter')\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        if mag_values:\n",
    "            axes[1].hist(mag_values, bins=20, alpha=0.7, edgecolor='black', color='green')\n",
    "            axes[1].set_xlabel('Magnitude values')\n",
    "            axes[1].set_ylabel('Frequency')\n",
    "            axes[1].set_title('Distribution of Magnitude parameters')\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('header_parameter_distributions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcc43ed-7fe7-48d9-8fb8-0169e11cc272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:27.826480Z",
     "iopub.status.busy": "2025-11-13T17:30:27.826327Z",
     "iopub.status.idle": "2025-11-13T17:30:27.830750Z",
     "shell.execute_reply": "2025-11-13T17:30:27.830141Z",
     "shell.execute_reply.started": "2025-11-13T17:30:27.826469Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_summary_statistics(all_parameters):\n",
    "    \"\"\"\n",
    "    Print summary statistics for the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_lightcurves = 0\n",
    "    all_num_points = []\n",
    "    \n",
    "    for tar_file, file_params_list in all_parameters.items():\n",
    "        num_in_file = len(file_params_list)\n",
    "        total_lightcurves += num_in_file\n",
    "        print(f\"\\n{tar_file}: {num_in_file} lightcurves\")\n",
    "        \n",
    "        for file_params in file_params_list:\n",
    "            all_num_points.append(file_params['data_stats']['num_points'])\n",
    "    \n",
    "    if total_lightcurves == 0:\n",
    "        print(\"\\nNo lightcurves found in any files!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal lightcurves across all files: {total_lightcurves}\")\n",
    "    if all_num_points:\n",
    "        print(f\"Average number of data points per lightcurve: {np.mean(all_num_points):.1f}\")\n",
    "        print(f\"Median number of data points per lightcurve: {np.median(all_num_points):.1f}\")\n",
    "        print(f\"Range of data points: {np.min(all_num_points)} - {np.max(all_num_points)}\")\n",
    "    else:\n",
    "        print(\"No data points found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d84f56-3519-4ec3-a8c5-0a6c2376d538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:30:28.027246Z",
     "iopub.status.busy": "2025-11-13T17:30:28.026964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 tar files to process\n",
      "  Found 114 total files in extracted directory\n",
      "  Found 97 total files in extracted directory\n",
      "  Found 98 total files in extracted directory\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all lightcurve files and generate plots\n",
    "    \"\"\"\n",
    "    #print(\"Starting lightcurve data analysis...\")\n",
    "    #print(\"Looking for tar files in current directory...\")\n",
    "    #print(\"Files found:\", [f for f in os.listdir('.') if f.endswith('.tar.gz')])\n",
    "    \n",
    "    # Process all tar files\n",
    "    all_parameters = extract_and_process_tar_files()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print_summary_statistics(all_parameters)\n",
    "    \n",
    "    # Generate distribution plots if we have data\n",
    "    if any(len(params) > 0 for params in all_parameters.values()):\n",
    "        plot_parameter_distributions(all_parameters)\n",
    "        print(\"\\nAnalysis complete!\")\n",
    "    else:\n",
    "        print(\"\\nNo lightcurve data found to analyze!\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74187580-8310-44ea-a471-8f658c073652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DL,Py3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
